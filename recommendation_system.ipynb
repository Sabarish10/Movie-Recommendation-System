{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will build a recommender system using the Movie Lens -100k dataset available here. https://grouplens.org/datasets/movielens/100k/. The dataset folder contains a number of files. I will be using the 'ua.base' file which contains 90,000 ratings and the 'ua.test' file which contains 10,000.\n",
    "\n",
    "The recommendation system I will build will be user-user based collaborative filtering and item-item based collaborative filtering and later go onto try a model based collaborative filtering using Singular Value Decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading both the datasets and setting the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  unix_timestamp\n",
       "0        1         1       5       874965758\n",
       "1        1         2       3       876893171\n",
       "2        1         3       4       878542960\n",
       "3        1         4       3       876893119\n",
       "4        1         5       3       889751712"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column user_id contains ids' of users starting from 1, the column movie_id contains ids' of users starting from 1 and the 'rating' column contains the corresponding ratings. Let us see how many unique users and how many unique movies(items) are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_base = ratings_base['user_id'].unique().max()\n",
    "n_items_base = ratings_base['movie_id'].unique().max()\n",
    "n_users_base,n_items_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 943 users and 1682 movies in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1664)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_test = ratings_test['user_id'].unique().max()\n",
    "n_items_test = ratings_test['movie_id'].unique().max()\n",
    "n_users_test,n_items_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating user-item matrix\n",
    "\n",
    "There are 943 users and 1664 movies in the training set. Now let us go ahead and create our user-item matrices, test_matrix and train_matrix which contain number of rows equal to the number of unique users and number of columns equal to the number of unique movies. The cells of this matrix are filled with the corresponding rating a user has given to a movie. If a user has not rated a movie then the cell is filled with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_matrix = np.zeros((n_users_base, n_items_base))\n",
    "for line in ratings_base.itertuples():\n",
    "    train_matrix[line[1]-1,line[2]-1] = line[3]\n",
    "    \n",
    "test_matrix = np.zeros((n_users_test, n_items_test))\n",
    "for line in ratings_test.itertuples():\n",
    "    test_matrix[line[1]-1,line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying user-user based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach we try is user-user based collaborative filtering. In this method, we first create a similarity matrix which specifies the similarity between two users based on the ratinngs they have given to different movies. We use the cosine similarity metric which computers the dot product between the two vectors made up of the ratings of the movies they have rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (943, 943)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.85324924,  0.9493235 , ...,  0.96129522,\n",
       "         0.8272823 ,  0.61960392],\n",
       "       [ 0.85324924,  0.        ,  0.87419215, ...,  0.82629308,\n",
       "         0.82681535,  0.91905667],\n",
       "       [ 0.9493235 ,  0.87419215,  0.        , ...,  0.97201154,\n",
       "         0.87518372,  0.97030738],\n",
       "       ..., \n",
       "       [ 0.96129522,  0.82629308,  0.97201154, ...,  0.        ,\n",
       "         0.96004871,  0.98085615],\n",
       "       [ 0.8272823 ,  0.82681535,  0.87518372, ...,  0.96004871,\n",
       "         0.        ,  0.85528944],\n",
       "       [ 0.61960392,  0.91905667,  0.97030738, ...,  0.98085615,\n",
       "         0.85528944,  0.        ]])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity = pairwise_distances(train_matrix, metric='cosine')\n",
    "print('shape: ',user_similarity.shape)\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity matrix has a shape of 943 x 943 as expected with each cell corresponding to the similarity between two users. Now we will write a prediction function which will predict the values in the user-item matrix. We will only consider the top n users which are similar to a user to make predictions for that user. In the formula we normalise the ratings of users by subtracting the mean rating of a user from every rating given by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\hat{x}_{k,m} =\\bar{x}_{k} + \\frac{\\sum\\limits_{u_a} sim_u(u_k, u_a) (x_{a,m} - \\bar{x}_{u_a})}{\\sum\\limits_{u_a}|sim_u(u_k, u_a)|}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_user(train_matrix, user_similarity, n_similar=30):\n",
    "    similar_n = user_similarity.argsort()[:,-n_similar:][:,::-1]\n",
    "    pred = np.zeros((n_users_base,n_items_base))\n",
    "    for i,users in enumerate(similar_n):\n",
    "        similar_users_indexes = users\n",
    "        similarity_n = user_similarity[i,similar_users_indexes]\n",
    "        matrix_n = train_matrix[similar_users_indexes,:]\n",
    "        rated_items = similarity_n[:,np.newaxis].T.dot(matrix_n - matrix_n.mean(axis=1)[:,np.newaxis])/ similarity_n.sum()\n",
    "        pred[i,:]  = rated_items\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function to find the predicted ratings and add the average rating of every use to give back the final predicted ratings. Here, we are considering the top 50 users which are similar to our user and using their ratings to predict our user's ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape  (943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.53079191,  0.53079191,  0.53079191, ...,  0.53079191,\n",
       "         0.53079191,  0.53079191],\n",
       "       [ 0.27556554,  0.17581381, -0.00189689, ..., -0.00189689,\n",
       "        -0.00189689, -0.00189689],\n",
       "       [ 1.17064209,  0.07064209,  0.01064209, ...,  0.01064209,\n",
       "         0.01064209,  0.01064209],\n",
       "       ..., \n",
       "       [-0.0479786 , -0.0479786 , -0.0479786 , ..., -0.0479786 ,\n",
       "        -0.0479786 , -0.0479786 ],\n",
       "       [ 0.8909642 ,  0.12995357,  0.12995357, ...,  0.12995357,\n",
       "         0.12995357,  0.12995357],\n",
       "       [ 0.27315101,  0.27315101,  0.27315101, ...,  0.31315101,\n",
       "         0.27315101,  0.27315101]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_user_user(train_matrix,user_similarity, 50) + train_matrix.mean(axis=1)[:, np.newaxis]\n",
    "print('predictions shape ',predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider only those ratings which are not zero in the test matrix and use them to find the error in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_ratings = predictions[test_matrix.nonzero()]\n",
    "test_truth = test_matrix[test_matrix.nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.507744099069281"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(predicted_ratings,test_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying item-item based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will go on and try item-item based collaborative filtering. This method finds the similarity between items instead of users, exactly like the previous method using 'cosine similarity'. Using the similarity between items and the users rating for similar items, we find the predicted ratings for un-rated items. Let us make the item similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 1682)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity = pairwise_distances(train_matrix.T, metric = 'cosine')\n",
    "item_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.59704074,  0.66673863, ...,  1.        ,\n",
       "         0.94919585,  0.94919585],\n",
       "       [ 0.59704074,  0.        ,  0.7308149 , ...,  1.        ,\n",
       "         0.91844091,  0.91844091],\n",
       "       [ 0.66673863,  0.7308149 ,  0.        , ...,  1.        ,\n",
       "         1.        ,  0.90098525],\n",
       "       ..., \n",
       "       [ 1.        ,  1.        ,  1.        , ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.94919585,  0.91844091,  1.        , ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.94919585,  0.91844091,  0.90098525, ...,  1.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity matrix has a shape of 1682 x 1682 as expected with each cell corresponding to the similarity between two users. Now we will write a prediction function which will predict the values in the user-item matrix. We will only consider the top n items which are similar to a item to make predictions.. In this formula we don't need normalise the ratings of users as we are using items to make predictions instead of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\hat{x}_{k,m} = \\frac{\\sum\\limits_{i_b} sim_i(i_m, i_b) (x_{k,b}) }{\\sum\\limits_{i_b}|sim_i(i_m, i_b)|}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_item_item(train_matrix, item_similarity, n_similar=30):\n",
    "    similar_n = item_similarity.argsort()[:,-n_similar:][:,::-1]\n",
    "    print('similar_n shape: ', similar_n.shape)\n",
    "    pred = np.zeros((n_users_base,n_items_base))\n",
    "    \n",
    "    for i,items in enumerate(similar_n):\n",
    "        similar_items_indexes = items\n",
    "        similarity_n = item_similarity[i,similar_items_indexes]\n",
    "        matrix_n = train_matrix[:,similar_items_indexes]\n",
    "        rated_items = matrix_n.dot(similarity_n)/similarity_n.sum()\n",
    "        pred[:,i]  = rated_items\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function to find the predicted ratings. Here, we are considering the top 50 users which are similar to our user and using their ratings to predict our user's ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar_n shape:  (1682, 50)\n",
      "predictions shape  (943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.66],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       ..., \n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.1 ,  0.08,  0.08],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.44,  0.2 ,  0.06]])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_item_item(train_matrix,item_similarity,50)\n",
    "print('predictions shape ',predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider only those ratings which are not zero in the test matrix and use them to find the error in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.749688827167227"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = predictions[test_matrix.nonzero()]\n",
    "test_truth = test_matrix[test_matrix.nonzero()]\n",
    "math.sqrt(mean_squared_error(predicted_ratings,test_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting recommendations for a user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part we get recommendations for a user based on the highest predicted ratings for a particular user. Let us get predctions for the user with user id 77. I am using the predictions from the item-item collaborative filtering model for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id = 77\n",
    "user_ratings = predictions[user_id-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the indices of the movies in the matrix which have not been rated by the user i.e. value is 0 and get their predticted ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    4, ..., 1679, 1680, 1681], dtype=int64)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unkown_indices = np.where(train_matrix[user_id-1,:] == 0)[0]\n",
    "train_unkown_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_recommendations = user_ratings[train_unkown_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1620,)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_recommendations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go on and print the top 5 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for user 77 are the movies: \n",
      "\n",
      "1426\n",
      "1356\n",
      "1316\n",
      "1100\n",
      "1374\n"
     ]
    }
   ],
   "source": [
    "print('\\nRecommendations for user {} are the movies: \\n'.format(user_id))\n",
    "for movie_id in user_recommendations.argsort()[-5:][: : -1]:\n",
    "    print(movie_id +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trying singular value decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have tried out both the memory based methods i.e user-user and item-item collaborative filtering, in this method we will try a model-based method. Singular value decomposition is a mathematical techinique used to find the missing values in a matrix. It decomposes a matrix into three matrices two of which are rectangular and the middle one is a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "X=U \\times S \\times V^T\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u, s, vt = svds(train_matrix, k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 20), (20,), (20, 1682))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape, s.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_diag_matrix = np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the predictions by finding the dot product of the three matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_svd = np.dot(np.dot(u,s_diag_matrix),vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8258075694458307"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings_svd = predictions_svd[test_matrix.nonzero()]\n",
    "test_truth = test_matrix[test_matrix.nonzero()]\n",
    "math.sqrt(mean_squared_error(predicted_ratings_svd,test_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The root mean square error is the least using this method. Let us now get the recommendations for user 33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1668,)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 33\n",
    "user_ratings = predictions_svd[user_id-1,:]\n",
    "train_unkown_indices = np.where(train_matrix[user_id-1,:] == 0)[0]\n",
    "user_recommendations = user_ratings[train_unkown_indices]\n",
    "user_recommendations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for user 33 are the movies: \n",
      "\n",
      "257\n",
      "321\n",
      "736\n",
      "325\n",
      "319\n"
     ]
    }
   ],
   "source": [
    "print('\\nRecommendations for user {} are the movies: \\n'.format(user_id))\n",
    "for movie_id in user_recommendations.argsort()[-5:][: : -1]:\n",
    "    print(movie_id +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all about recommendation systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
